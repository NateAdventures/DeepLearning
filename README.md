#CV_Finals results:
## Выводы

В работе реализован пайплайн классификации биологических изображений на малом и сильно несбалансированном датасете (3 класса: `amoeba`, `Leegaardiella_ovalis`, `Mesodinium_sp`).

### Основные результаты
- **Scratch CNN (обучение с нуля)** показала лучший результат на валидации: **val_accuracy = 0.9286** (train_accuracy = 0.9182).  
- **ResNet50 (frozen, только классификатор)** не улучшила качество: **val_accuracy = 0.9107**.
- **ResNet50 partial fine-tuning (разморозка последних 50 слоёв)** дала **val_accuracy = 0.9286** при высокой train_accuracy = **0.9545**, но обучение было нестабильным (скачки `val_loss` до ~81).
- **ResNet50 full fine-tuning** показала **val_accuracy = 0.9107** при train_accuracy = **0.9364** и крайне нестабильном `val_loss` (очень большие значения), что указывает на переобучение/проблемы оптимизации на малом датасете.

### Дополнительные наблюдения
- Размер батча **8/16/32** (ResNet frozen) **не повлиял** на результат: во всех случаях **max val_accuracy = 0.9107**.
- Из-за дисбаланса (252 vs 14 vs 11 изображений) модель уверенно распознаёт `Mesodinium_sp`, но часто путает редкие классы, что показывает: высокая **accuracy** может скрывать плохое качество для minority-классов.
- **TTA (15 аугментаций на инференсе)** не улучшила качество: **accuracy = 0.9107**.

### Итог
Для данного малого и несбалансированного датасета наиболее практичным решением оказалась **простая CNN**, обучаемая с нуля (**0.9286** на валидации). Улучшение качества стоит искать в **балансировке классов** (class weights/oversampling), **изменении функции потерь** (например, focal loss) и более корректной оценке качества (macro-F1), а не в усложнении архитектуры.

В дальнейшем целесообразно исследовать методы балансировки классов, использование взвешенных функций потерь, а также self-supervised подходы предварительного обучения, адаптированные под биологические изображения.
