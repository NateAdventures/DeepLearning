#CV_Finals results:
## 1. Pipeline Overview

В работе реализован полный пайплайн классификации биологических микроскопических изображений для малого и несбалансированного датасета (3 класса: `amoeba`, `Leegaardiella_ovalis`, `Mesodinium_sp`).  
Пайплайн включает предобработку изображений, аугментацию данных, обучение моделей (с нуля и с transfer learning), а также сравнительный анализ различных стратегий обучения.

---

## 2. Предобработка и проектные решения

### Базовая предобработка
- Приведение изображений к единому размеру **128×128**
- Перевод в **grayscale** для снижения размерности
- Нормализация интенсивности в диапазон **[0,1]**

унификация входных данных необходима для стабильного обучения CNN и корректной работы оптимизаторов.

### Фильтрация изображений
Использованы:
- **Gaussian Blur (3×3, σ=1)** — подавление шумов без разрушения структуры
- **CLAHE** — локальная коррекция контраста

**Не использовались** морфологические операции, сильные blur и агрессивный sharpening, так как они искажают морфологические признаки.

---

## 3. Аугментация данных

Используемые аугментации:
- Повороты (±15°)
- Сдвиги (до 10%)
- Небольшой zoom
- Горизонтальный flip

Агрессивные геометрические деформации и сильные искажения формы не применялись.

---

## 4. Архитектуры и стратегии обучения

### Модель с нуля
- Компактная CNN (3 Conv-блока + Dropout)
- Цель: минимизировать переобучение на малом датасете

### Предобученная модель
Использована **ResNet50 (ImageNet)**, протестированы стратегии:
1. **Frozen** — обучение только классификатора  
2. **Partial fine-tuning** — разморозка последних 50 слоёв  
3. **Full fine-tuning** — разморозка всей сети

---

## 5. Результаты экспериментов

### Сравнение моделей

| Модель            | Train Accuracy | Val Accuracy |
|------------------|---------------|--------------|
| Scratch CNN      | 0.9182        | **0.9286**   |
| ResNet (frozen)  | 0.9136        | 0.9107      |
| ResNet (partial) | 0.9545        | **0.9286**  |
| ResNet (full)    | 0.9364        | 0.9107      |

### Влияние размера батча (ResNet frozen)

| Batch size | Max Val Accuracy |
|-----------|------------------|
| 8         | 0.9107           |
| 16        | 0.9107           |
| 32        | 0.9107           |

---

## 6. Анализ результатов

- **Scratch CNN** показала наиболее стабильное обобщение и лучший результат на валидации.
- **ResNet frozen** не смогла адаптироваться к специфике микроскопических изображений.
- **Partial fine-tuning** дал высокий train acc, но сопровождался нестабильным `val_loss`, что указывает на риск переобучения.
- **Full fine-tuning** оказался неэффективным из-за малого объёма данных.
- Размер батча не оказал влияния на качество.
- Из-за сильной несбалансированности модель уверенно классифицирует `Mesodinium_sp`, но плохо распознаёт редкие классы.
- Test-Time Augmentation совсем не улучшил итоговую точность.

---

## 7. Итоговый вывод

Для данной задачи наиболее эффективной стратегией является **использование компактной CNN, обучаемой с нуля**, с умеренными аугментациями и контролем переобучения (**val_accuracy = 0.9286**).  
Transfer learning с ResNet50 не дал преимущества из-за малого и несбалансированного датасета.

### Перспективы
- балансировка классов (class weights, oversampling);
- использование модифицированных функций потерь (например, focal loss);
- self-supervised предварительное обучение для биологических изображений.

В дальнейшем целесообразно исследовать методы балансировки классов, использование взвешенных функций потерь, а также self-supervised подходы предварительного обучения, адаптированные под биологические изображения.
